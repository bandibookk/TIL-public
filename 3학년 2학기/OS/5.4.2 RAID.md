# RAID : Hamming Word 다시 보기
CPU의 성능은 끔찍하게 빠른 속도로 발전해왔다. 무어의 법칙에 따라 CPU는 매 18 ~ 24 개월 마다 2배의 규모로 증가하였는데, 디스크의 성능은 그렇지 못했다.. <br>
Patterson은 디스크의 성능, 안정성 모두를 향상시켜줄 수 있는 6개로 구성된 디스크 구성안을 제안했는데, 이를 RAID라고 부른다. <br>

# Redundant Array of Independent Disk
RAID는 본래 Redundant Array of Inexpensive Disk에서 이름이 유래되었다. 패터슨은 원래, **같은 데이터를 가지고 있는 데이터 여러개를 사용하자!** 라는 의미로 RAID를 제안했으나, 산업계에서는 Inexpensive라는 단어를 맘에 들지 않아 해서 Independent로 대체 되었다. <br>
RAID는 **같은 내용이 담긴 독립적인 지스크 여러개를 사용하자는 방식인 것이다.** <br>
이와 반대되는 개념으로는 SLED(Single Large Expensive Disk)가 있다.

## Level 0 : Striping 분산!
![level 0, 1](https://user-images.githubusercontent.com/71186266/205442798-3dfcffcf-35ea-4d9a-bb2a-11f06892bc98.png)


Level 0는 스트라이핑 기법을 통해 데이터를 여러 드라이브에 분산한다. 

**\<장점>**

1. 여러 디스크가 여러 섹터 연산을 동시에 수행하기 떄문에, **요청이 크면 클 수록 성능이 좋다!**

**\<단점>**
1. 병렬성이 존재하지 않는 요청에 이익이 별로 없음. <br> 예를 들어, **'작은' '한 디스크에' '여러번'의 요청이 들어가는 경우 딱히 이득은 없다.**
2. 안정성이 SLED보다도 낮을 수 있음. <br> 여러 개의 디스크를 사용하는 만큼, 각 디스크의 고장률 X 디스크 갯수 만큼의 높은 고장률을 가진다. 
3. 사실 중복성이 존재하지 않아 제대로 된 RAID는 아니다.


## Level 1 : Redandancy!
![level 0, 1](https://user-images.githubusercontent.com/71186266/205442798-3dfcffcf-35ea-4d9a-bb2a-11f06892bc98.png)

Level 1이야 말로 진정한 RAID이다. 
**Level 1은 모든 디스크들을 중복시킨다. 4개의 주요 디스크와 4개의 백업 디스크가 있다.** <br>
덕분에 **읽기 연산시 성능이 2배나 좋다!! 복사물까지 사용할 수 있어, 부하를 분배할 수 있다.** <br>
**항상 복사체가 존재하므로, 손실에도 강하다!** 크래쉬 되도 딴거 쓰면 그만이야~~

**\<단점>**
- 대신에 모든 strip는 쓰기시 2번씩 쓰여 진다. 2배 느린 정도는 아니지만 좋은 건 아니다.

## Level 2 : Parity!
![level 2](https://user-images.githubusercontent.com/71186266/205442800-40cde63d-6162-42cc-8ea7-2e619f02c7f9.png)

레벨 2는 **워드나 바이트 단위로 동작한다.** -> **bit 단위로 쪼게진다.** <br>
개별
7개의 드라이브를 사용하는데, 이 중 1, 2, 4 비트는 패리티 비트이다. 일곱 개의 드라이브에 7비트 Hamming Code 방식의 워드를 드라이브 당 한 비트씩 쓴다. (잘 이해가 안 간다.) <br> <br>

하나의 섹터 시간에 32개 섹터의 가치가 있는 데이터를 쓸 수 있기 때문에 전체 처리율이 막대하고, 읽기 중 하나의 드라이브를 잃게 되더라도 해밍 코드 메커니즘에 의해 실행 중에 즉시 문제를 해결할 수 있다. (잘 이해 안 감) <br>

여하튼 종합해보자면, Hamming 코드라는 것을 더해서 Parity Bit를 추가한다. 이걸로 Error가 발생한 곳을 정확히 짚어낼 수 있다. <br> <br>

에러를 찾는 예시를 하나만 보자. <br> 
기본적으로 1 bit만에서만 에러가 발생했다고 가정한다. 그리고 even parity 방식을 사용할 것이다. <br>
even parity 방식은 parity 비트가 아닌 비트들의 값의 합이 **짝수가 되도록** parity값을 정해주는 것이다. <br>

예를 들어, 1번 bit가 parity bit일 때, 

|  bit  |   1   |   3   |   5   |   7   |
| :---: | :---: | :---: | :---: | :---: |
| value |   ?   |   1   |   1   |   1   |

위와 같이 3, 5, 7 비트 값이 설정되어 있다고 하자. **even parity에서 세 비트값의 합은 홀수인 3이므로, 1번 비트의 값은 1이 된다.** <br> <br>

이러한 evne parity 비트를 이용해서 문제가 발생한 bit를 찾아 보자. 1, 2, 4가 parity bit <br>
|  bit  |   1   |   3   |   5   |   7   |
| :---: | :---: | :---: | :---: | :---: |
| value |   0   |   1   |   1   |   1   |

|  bit  |   2   |   3   |   6   |   7   |
| :---: | :---: | :---: | :---: | :---: |
| value |   1   |   1   |   1   |   1   |

|  bit  |   4   |   5   |   6   |   7   |
| :---: | :---: | :---: | :---: | :---: |
| value |   0   |   1   |   1   |   1   |

위와 같은 상황에서 오류가 발생한 곳을 찾아보자.
1. 1번 표에서 3, 5, 7 bit 값의 합은 3인데, 1번 bit가 0이다? **뭔가 잘못 됨..** <br> **-> 범인은 3, 5, 7 중에 하나이다!**
2. 2번 표에서 3, 6, 7의 합은 3이고, 2까지 더하면 4로 짝수가 완성된다. **고로, 3과 7은 문제 비트가 아니다.**
3. 결국 5번 비트가 에러 비트인 것으로 결정되었다.
4. 마지막 표도 5번 비트가 1이 아닌 0이라면 말이 된다. **확실히 5번 비트가 에러 비트임을 확인했다.**

**\<level 2의 단점>**
1. 7개의 drive가 항상 **arm 위치나 회전 위치에 대해** 동기화 되어야 한다.
2. **컨트롤러가 Hamming Checksum을 매 bit time마다 해야한다!** 그러니까, 에러 체크를 계속 하는데 이는 overhead로 작용한다.


# Level 3 : Single Parity Drive!
![level 3](https://user-images.githubusercontent.com/71186266/205442802-4abb19a8-9d7d-4789-8189-54a9a66852c7.png)



**하나의 패러티 Drive를 둔다.** Level 3에서 **단일 패러티 비트는** 각 데이터 워드 마다 계산되어 **패리티 드라이브에 쓰여진다.**


**\<단점>**
1. bit 단위 구성의 숙명... **개별 데이터 워드들이 여러 드라이브에 분산되어 있기 때문에, 모든 드라이브들이 항상 정확히 Synchronized 되어 있어야 한다..**
2. level 2, 3은 모두 매우 높은 데이터 전송률을 보이지만, 이들이 다룰 수 있는 초당 입출력 요청 수는 단일 드라이브 보다 높지 못하다 ?? 

## Level 4 : 다시 Strip으로
![level 4, 5](https://user-images.githubusercontent.com/71186266/205442803-e631f292-df19-40e4-b6d5-9a22af07d1b3.png)
다시 Strip으로.. Level 4부터는 `패리티가 있는 개별 워드`가 아니라 **다시 Strip으로 동작한다!** 즉, **동기화된 드라이브를 요구하지 않는다!!** <br>

그림과 같이 여분의 드라이브에 Strip을 위한 **Strip Parity가 존재한다.** <br>
각 스트립이 k byte라면, 모든 스트립은 함께 XOR되어, k 바이트 길이의 패리티 스트립이 된다. 만일 드라이브가 고장나면, 손실된 바이트는 전체 드라이브의 집합을 읽어, 패리티 드라이브로부터 재계산 될 수 있다. (정확히 어떻게 동작한다는건지 감이 잘 안 온다.) <br>


**\<단점>**

1. 작은 갱신에 대한 성능이 낮다 - **한 섹터만 변화해도, 패리티 계산을 위해 모든 드라이브를 읽고, 또 다시 쓰여야 한다.**
2. **패리티 드라이브에 대한 높은 부하** - 때문에 병목 현상이 발생할 수 있음.

## Level 5 : Parity Bit 분산
![level 4, 5](https://user-images.githubusercontent.com/71186266/205442803-e631f292-df19-40e4-b6d5-9a22af07d1b3.png)
이러한 level 4의 Parity Drive Bottleneck을 해결하기 위해 **Parity Bit들을 모~든 드라이브에 Round Robin 방식으로 분산해주었다!** <br>

**\<단점>**
대신, 드라이브가 failed - 고장난 경우에 드라이브 내용을 복구하는 것이 매우 복잡하다! (물어 보자.)

## Reference
- Modern Operating Systems <ANDRWE S. TANENBAUM 저>
