# 7. 메모리 관리

## 1. 주소 바인딩
프로세스들의 정보는 어디에 저장되고 관리될까? <br>
프로그램을 실행하려면, 아주 당연하게도 해당 프로그램과 관련된 정보들이 어딘가에 담겨 있어야하고, 그 정보들을 끌어올 수 있어야 한다. <Br>
프로그램이 실행을 위해 메모리에 적재되면 해당 프로세스를 위한 독자적인 주소 공간이 생성된다. <Br>
**이 주소를 논리적 주소 혹은 가상 주소라고 부른다.** <br>

논리적 주소는 말 그대로 실제로 물리적인 주소가 아니라, 각 프로세스별로 독립적으로! 임의로 할당되는 '논리적인' 주소이다. <br>
물리적 주소는 말 그대로 0 부터 시작되는 메모리의 주소들로 보통 아래쪽에 OS를 올려 두고, 위 쪽에는 사용자 프로세스들이 올라가 있다. <br>
프로세스가 원활하게 실행되려면, 데이터를 쉽게 꺼내올 수 있어야 한다 -> **꼭 메모리 위에 올라가 있어야 하는데,** 논리적 주소들을 실제 물리 주소로 연결해 주는 작업을 **주소 바인딩이라고 부른다.** <br> <br>

주소 바인딩에는 프로그램이 실제로 적재되는 물리 메모리 주소가 결정되는 타이밍에 따라 세가지로 나뉠 수 있다. `컴파일 타임 바인딩`, `로드 타임 바인딩`, 그리고 `실행시간 바인딩`으로 나뉜다. <Br>
이름과 같은 바인딩 타이밍을 가지고 있다. 앞의 두 바인딩은 비효율적이다. 왜냐하면, 컴파일 타임에 올려 두던, 프로그램 로딩 타이밍에 올려 두던 어떻게 보면 실행 상황과 관계 없이 **미리 올려두는 것** 이 되는데, 유연하게 대응할 수 없다. <Br>
**실행 시간 바인딩은 프로그램이 실행된 뒤에도 메모리상의 주소를 변경할 수 있다.** <br>
이런 방식은 메모리에 프로그램 실행에 있어 당장 필요한 부분만 그때 그때 올려 놓는 방식의 기틀이 되기 때문에 중요하다. <br>
이런 방식에의 어려움은
CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지 알 수 있어야 한다는 점이다. <br>
그 때 그 때 위치가 바뀌므로, 이를 정리해둘 곳이 필요한데, 이를 **주소 매핑 테이블이라고 한다.** 주소 매핑 테이블을 통해 논리 주소가 실제로 가리키는 물리 주소를 파악할 수 있는 것이다.  <br>


### MMU scheme
안정적인 실행 시간 바인딩을 위해서는 **기준 레지스터와 한계 레지스터, 그리고 MMU등이 필요하다.** <br>

MMU는 하드웨어 장치로, CPU에게서 논리 주소를 받아, 물리 주소로 변환해주는 역할을 한다. <br>
MMU 덕분에 CPU는 물리 주소를 알 필요 없이, 논리 주소만을 이용해 필요한 정보를 모두 찾아낼 수 있다. <Br>

MMU는 **CPU로 부터 받은 논리적 주소에, 본인이 가지고 있는 오프셋인 기준 레지스터 값을 더한다. 그 결과는 데이터의 실제 물리 주소를 나타낸다.** <br>
그리고 **제한 레지스터는 현재 CPU가 실행중인 프로세스의 크기를 가지고 있는데, 이 한계 레지스터를 이용해서 혹시 다른 프로세스가 사용하고 있는 영역을 침범하지는 않는지 확인한다.** <br>
이 한계 레지스터를 통해 메모리 보안이 이루어진다. <br> <br>

### 정리
먼저 CPU가 요청한 프로세스의 논리적 주소값이 한계 레지스터 내에 저장된 프로세스의 크기보다 작은지 환인한 다음, 논리적 주소 값에 기준 레지스터 값을 더해 실제 물리 주소를 구한 다음, 해당 물리 메모리 위치에 접근한다! <Br>
**만약 논리적 주소의 값이 한계 레지스터 값보다 크다면 트랩을 발생시켜 해당 프로세스를 강제 종료 시킨다!**

## 2. 메모리 관련 용어
메모리 관련 용어들을 정리하자.
### 2.1 동적 로딩
동적 로딩은 여러 프로그램이 동시에 메모리에 올라가 수행되는 다중 프로그래밍 환경에서 메모리 사용의 효율을 높이기 위해 사용하는 기법으로, **프로세스가 시작될 때 그 프로세스의 주소 공간 전체를 메모리에 전부 올리지 않고! 당장 필요한 부분, 불리는 부분만 메모리에 적재하는 방식이다.** <br>
동적 로딩 방식 덕분에, 프로그램에서 필요도 없는 수 많은 부분들이 굳이 메모리에 전부 올라가지 않아도 되게 되었고, 한 메모리에 더 많은 프로세스를 적재할 수 있게 되었으며, 메모리 보다도 큰 크기의 프로세스를 올릴 수 있게 되었다!! <Br>
이래저래 혁신적인 방식!

### 2.2 동적 연결
연결이란 프로그래머가 작성한 소스코드를 컴파일하여 생성된 목적 파일과, 이미 컴파일된 라리브러리 파일을 묶어 하나의 실행 파일을 만드는 것이다. <br>
그리고 **동적 연결이란, 목적 파일과 라이브러리의 연결을 프로그램 실행 시점까지 지연 시키는 것이다.** <br>
덕분에 실행파일의 크기도 상대적으로 작아졌고, 만약에 같은 라이브러리를 여러 프로세스가 사용하는 상황에서 원래대로라면, `A + 라이브러리 R`, `B + 라이브러리 R` 이렇게 두개가 모두 올라가야 하는 상황을, 라이브러리가 실행 시점에 연결되므로, 예방할 수 있는 것이다! `A`, `B`, `R` 이런 식으로! <br>
라이브러리 호출시 해당 라이브러리가 이미 메모리에 있다면, 그 주소의 메모리 위치에서 직접 참조해서 사용한다! <br>

## 3. 물리적 메모리 할당 방식
운영체제가 상주하고 있는 영역 외의 사용자 프로세스 영역의 관리 방법에 대해 살펴보자. <br>
사용자 프로세스 영역의 관리 방법은 프로세스를 메모리에 올리는 방법에 따라 크게 연속할당과 불연속 할당으로 니뉜다. <br>
연속 할당에는 고정분할과 가변분할 방식의 두 가지 방식이 있고, 불연속 할당에 대해서는 다른 글에서 다룰 것이다. <Br>

### 연속할당 방식
연속할당 방식은 말 그대로 주소공간을 분할하지 않고 물리적 메모리의 한 곳에 연속적으로 적재하는 방식이다. <br>


여기서 물리적 메모리를 고정된 크기의 분할로 미리 나누어 놓는지 아닌지에 따라 고정분할 방식과 가변분할 방식으로 나뉜다. <Br>
연속할당 방식은 내부 조각과 외부 조각 문제가 발생한다. 고정분할 방식은 둘 다 발생하고, 가변분할 방식의 경우 외부 조각 문제가 발생할 수 있다. <Br>
물론 외부 조각 문제를 해결하기 위해 빈 공간들을 모으는 `Compaction` 기능이 도입되었지만, 메모리 공간 내에서 여러 프로세스들이 사용하는 구역을 재배치하는 작업..은 정말 큰 오버헤드가 발생한다. <Br>
우리가 컴퓨터에서 쓰는 메모리나 디스크에선 이런 문제가 덜 발생하는 불연속 할당 방식이 더욱 선호된다. <Br>
이 글에서는 연속할당 방식까지만 알아보자. <br>

### 고정분할과 가변분할
**고정분할 방식은 물리적 메모리를 주어진 개수만큼의 영구적인 Partition으로 미리 나누어 두고 각 분할에 하나의 프로세스를 적재해 실행시킬 수 있게 하는 방식이다.** <br>

분할의 크기를 동일하게 하던 서로 다르게 하건 그것은 자유지만, **하나의 분할에는 하나의 프로그램만을 적재할 수 있다.** <br>
따라서 동시에 메모리에 올릴 수 있는 양이 고정되어 있고, 빈 공간들이 아주 제각각이 될 것이다. <Br>
서랍장에 물건들을 넣는 것을 상상해보자. 물건들의 크기가 전부 같건 틀리건 간에, 물건들 사이 사이에 쓸대없는 빈 공간들이 발생하게 되고, 이로 인해서 분명 공간이 남았는데도 물건이 들어가지 못 하는 비효율적인 상황이 발생한다. <Br>
빈 공간을 전부 합친다고 상상해보면 새로운 물건을 더 넣을 수 있지 않는가.. 이런 상황을 **외부조각이라고 한다.** <br>
아니면 프로그램들의 크기가 재각각이다 보니, 너무 작은 프로그램은 큰 크기를 할당 받는 상황이 생길 수도 있다. <br>
예를 들어 서랍장에 물건을 잘 넣고 싶으니 상자들을 제공해줬는데, 상자보다 너무 작은 물건을 넣어 비효율이 발생하는 것이다. **이런 상황을 내부조각이라고 한다.**

<br> <br>

**가변분할은 고정 분할 방식과는 다르게 메모리에 적재되는 프로그램 크기에 따라 분할의 크기나 개수를 동적으로 바꾸어 주는 상황이다.** <br>
이제 크기가 제각각이다보니, 내부조각은 발생하지 않게 된다. 하지만 어떻게 배치하느냐가 너무 중요해졌다. <Br>
프로세스가 종료되면 빈 공간이 생겨나기 때문에 배치를 잘 한 경우, 이 빈 공간에 다음 프로세스를 쏙 넣어줄 수 있겠지만, <br>
반대로 잘못 배치해주면 프로세스들이 종료됨에 따라 애매~한 크기의 공간들이 생겨나게 될 수도 있다. <Br>
이런 문제를 **동적 메모리 할당 문제라고도 부른다.** <br>

### 동적 메모리 할당 문제
이런 동적 메모리 할당 문제 해결하는 여러 방법이 있다. 빈 공간의 '어디에' 다음 프로세스를 넣을 것이냐? 하는 고민인 것이다. <Br>
1. **최초 적합:** 들어갈 수 있는 크기의 빈공간을 찾으면 바로 들어간다 => 시간적으로 효율적이라고 할 수 있다!
2. **최적 적합:** 가용 공간들을 살펴보고, 들어갈 수 있으면서 가장 작은 곳을 찾는다 => 모든 가용공간을 살피느라 오버헤드가 발생하고, 오히려 너무 작은 빈 공간들이 생겨날 수도 있다.
3. **최악 적합:** 가용 공간들 중 가장 큰 곳에 넣는다.. 왜 나온지 모르겠다. 무려 전부 뒤져본 다음에 가장 큰 곳에 넣는 것이다

실험에 따르면 이 중에서는 최악 적합이 최악이고 (왜 실험했을까) 최초적합과 최적적합이 속도와 공간 이용률 측면에서 좋다고 한다. 

### Compaction
이런 가변 분할 방식에서의 외부조각 문제를 해결하기 위해 컴팩션이 도입됐다. <Br>
앞서 언급한 것처럼 빈 공간들을 합쳐야 하는데, 현재 수행중인 프로세스들이 사용중이 메로리 영역을 아주 많이 움직이는 것이므로 오히려 옮기는게 더 오버헤드가 클 수도 있다.. <br>
그렇다고 그때 그때 효율적으로 컴팩션 하는 방법을 연구하자니 너무 어려웠다.. 동적인 상황에서만 이런 행위가 가능한 것은 물론이다.. <br>


### 불연속 할당 기법
불연속할당 기법은 연속할당 기법과 다르게 **하나의 프로세스를 물리적 메모리의 여러 위치에 분산되어 올리는 방식이다.** <br>
무식하게 연속으로 하지 않고, 일정한 분할 기준을 정해서 나누어서 메모리에 올리자는 것이다! <Br>
이런 불연속 할당 기법에는 페이징과 세그멘테이션 기법이 있다. 그리고 세그멘테이션 기법을 기본으로 하고, 페이징을 도입한 페이지드 세그먼테이션 방식이 있는데, 중요한 내용이므로, 다음 글에서 알아보자.

## Reference
- [반효경 교수 OS 강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323)
