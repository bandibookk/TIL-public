## 8.3 페이지 프레임의 할당
여러 프로세스가 동시에 수행될 때, 각 프로세스는 얼만큼의 메모리를 할당 받게 될까? <br>
그리고, **각 프로세스마다 페이지 프레임을 얼마나 할당 해주면 되는걸까?** <br>
페이지 프레임의 크기를 모두 균등하게 할당해 주는 `균등할당 (equal allocation)`도 하나의 방법이다. <Br>
하지만, 시스템의 성능 향상을 위한 **더 나은 메모리 할당 알고리즘이 존재한다.** <br>

1. `비례할당 (proportional allocation)`: 프로세스의 크기에 비례하여 할당해준다.
2. `우선순위 할당 (priority allocation)`: 프로세스의 우선순위에 따라 다르게 할당해준다. <Br> 여기서의 우선순위란 **당장 CPU에서 실행되는지 여부로** 당장 실행될 프로세스에게 나중에 수행될 프로세스보다 더 많은 페이지 프레임을 할당해주는 것이다.

<Br>

한편, 이런 알고리즘들 만으로 프로세스의 페이지 참조 특성을 모두 반영하지 못할 수도 있다. <br>

수행중인 프로세스가 너무 많다면, 프로세스당 너무 적은 양의 페이지 프레임을 할당 받게 되는데, 기본적으로 프로그램이 제대로 돌아가려면 여러 영역을 동시 다발적으로 접근한다는 점을 생각해보면, 계속해서 Page Fault가 발생할 것이 당연하다. <br>
반복문의 경우도 그렇다. 큰 사이즈의 반복문을 수행중인데, 반복문 전체를 올릴 만큼 페이지 프레임을 할당받지 못했다면.. 매 반복마다 계속 스왑아웃-인이 발생하게 되는 것이다. <Br>

페이지 프레임을 할당할 때는 이 모든 것을 고려해야한다. 심지어 어떤 프로세스의 메모리를 다 뺏더라도 다른 프로세스들에게 최소한의 메모리를 할당해줄 수 있어야 한다. 

## 8.2 Page Replacement Algoritm
Page Fault가 발생했을 때 메모리 페이지 프레임이 모두 할당되어 있다면, 새로운 페이지를 할당해주기 위해 할당된 페이지 프레임 중에 하나를 선택해서 스왑아웃 한다고 했었다. <br>
이를 `페이지 교체`라고 부른다. 모든 페이지들은 메모리에서 나가기 싫어할텐데 어떤 기준으로 스왑아웃할 페이지를 선택 해야할까? <br>

스왑아웃될 페이지를 결정하는 알고리즘을 `페이지 교체 알고리즘`이라고 부른다. <br>
알고리즘의 목표는 조만간 참조될 가능성이 가장 적은 페이지를 상정해서 페이지 폴트를 최소화 하는 것이다. <br>

다양한 페이지 교체 알고리즘을 알아보고 제시된 페이지 참조열로 직접 테스트해서 페이지 부재율을 비교해보자.
```
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
``` 
위의 숫자들은 참조되는 페이지들의 번호를 시간 순서대로 나열한 것이다. 위 숫자들로 비교해보겠다. <br>

메모리에 페이지가 이미 있는 경우를 `hit` 적중 되었다고 표현하고, 없는 경우를 `fault` 부재라고 부른다. <br>

### 1) 최적 페이지 교체 알고리즘
빌레디의 최적 알고리즘은 실시간 온라인 상황에 적용 가능한 알고리즘은 아니다. 페이지가 어떤 순서로 참조될지 미리 알고있다고 '생각하고' 가장 먼 미래에 참조될 페이지 부터 스왑아웃 시키는 알고리즘이다. <br>
당연히 온라인 상황에서 유저가 어떻게 프로그램을 사용할지는 예측할 수 없다. <br> 
이런 알고리즘은 계속해서 같은 수행을 하는 프로그램에나 적용이 가능하다. 그래서 이런 알고리즘을 `오프라인 알고리즘`이라고 부른다. <Br>
이런 뻔뻔한 알고리즘이 존재하는 이유는, **성능에 대한 지표가 되기 때문이다.** <br>
**일종의 상한을 알려주기 때문이다.** 페이지 교체 방식의 최선의 경우를 알려주기 때문에, 알고리즘의 성능을 가늠할 때도 좋고, 만약 어떤 알고리즘의 성능이 최적 페이지 교체 알고리즘과 유사하다면, 더 이상 디밸롭 할 필요가 없다는 것을 알 수 있다. <Br>
상상속의 최적의 알고리즘과 가깝다는 것은 더 발전시킬 때 엄청난 노력? 코스트가 필요하다는 것인데, 그렇게 해서 발전시켜봐야 최적 알고리즘까지가 상한이기 때문에, 더 디밸롭 할지 판단할 떄 좋은 기준이 된다. <Br>

![최적 페이지 교체 알고리즘](https://user-images.githubusercontent.com/71186266/212477888-d436c7ba-ddb0-4f0c-883a-a17b48caa9c0.jpg)



알고리즘은 위와 같이 진행된다. 처음 4회는 어쩔 수 없이 page fault가 일어난다. 페이지 5가 처음 참조되었을 때 fault가 발생했는데, 우리는 현재 남아있는 1, 2, 3, 4 중 4가 가장 늦게 참조될 것이란 것을 알고 있기 때문에, **4를 스왑아웃한다.** <br>
그리고 쭉 진행되어서 4가 참조될 때 fault가 발생했고, 마지막으로 5가 참조되는 것을 알고 있으므로, 1, 2, 3 중 아무거나 스왑아웃 시켰다. <br>

**이를 통해 우리는 최적의 상황이여도 6회의 page fault가 발생하는구나! 라고 가늠할 수가 있는 것이다.**

## 2) First In First Out
FIFO는 알고리즘 단골 유형인데, 말 그대로 정말 물리적으로 먼저 들어온 프로세스를 먼저 내보내는 것이다.

![FIFO](https://user-images.githubusercontent.com/71186266/212477889-1aa5bb13-aa21-4455-ae85-0b80c9a42a50.jpg)


위의 사진 처럼, 정말로 먼저 들어온 페이지를 먼저 내보낸다. 그러다보니 많은 page fault가 발생할 수 밖에 없다. 미래에 대한 고려가 1도 없기 때문이다. <Br>
먼저 들어왔다고 해서 가장 빠르게 다시 호출되나? 당연히 그럴리가 없다. <br>
최적에서 6번 발생하던 page fault가 10개로 늘었다. 심지어 그림과 같이 메모리 공간을 한칸 늘렸는데도, 무려 한칸 늘렸는데도 오히려 page fault가 더 늘어버린 것이다. <br>
그만큼 참 비효율적인 방법이다. 참고로 위와 같이 메모리를 늘렸는데 오히려 page fault가 늘어나는 상황을 FIFO Anomaly라고 부른다.


### 3) Least Recently Used - LRU
메모리 페이지의 참조 성향에는 시간지역성이라는 성질이 있다. <br>
시간지역성은 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높다는 ㅅ어질이다. <br>
LRU는 이런 성질을 이용해 **참조 시점이 가장 오래된 페이지를 스왑아웃한다.** <br>

![LRU](https://user-images.githubusercontent.com/71186266/212477885-a528737c-6244-41de-84bd-26124d434b27.jpg)


5번이 참조되었을 때를 잘 보면 1, 2, 3, 4 순서로 처음에 참조되었었는데, 이후 1, 2가 직전에 다시 참조 되었으므로 가장 참조 시점이 오래된 3이 스왑아웃 당한다. <br>
예시에서 8번의 page fault를 확인할 수 있었다.


### 4) Least Frequently Used - LFU
LFU 알고리즘은 페이지의 **참조 횟수로 교체 페이지를 결정한다.** <br>
참조 횟수 꼴지 페이지가 여러개인 경우 임으로 하나를 선정하여 쫒아낸다. 웬만하면 그 중 참조된지 더 오래된 페이지를 쫒아내는 것이 유리하다. <Br>

LFU는 참조 횟수를 세는 방식에 따라 `Incache-LFU`와 `Perfect-LFU`로 구현 가능하다. <br>
1. `Incache-LFU`: **물리 메모리에 올라온 이후 부터의 참조 횟수를 센다.**
2. `Perfect-LFU`: 페이지의 과거 총 참조 횟수까지 전부 카운팅한다. 그래서 `Perfect`라는 말이 붙었다. <br> 

당연히 Perfect가 좀 더 확실하고 정확하게 참조 횟수가 가능하지만, 메모리에 올라와 있지도 않은 모든 페이지의 참조 횟수를 저장하고 있어야 한다는 메모리 비효율이 크다. <br>
LFU는 LRU보다 훨씬 오래된 과거들을 고려할 수 있어서 좋다. (LFU가 길기 보다는 LRU가 짧은거다) <Br>
대신 비효율도 있고, 시간에 따른 페이지 참조의 변화를 반영하지 못한다. <br>
<!-- 어제 참조가 참 많이 되었다가 오늘 부터는 참조가 덜 될 예정인 페이지가 있을 때, 어제의 기록도 반영되기 때문에 시간에 따른 참조 성향의 변화를 반영하지 못 한다는 것이다. -->

```
1, 1, 1, 1, 2, 2, 3, 3, 2, 4, 5 ...
```
예를 들어 위와 같이 페이지가 참조된다고 해보자. 당연히 5에서 Page Fault가 발생한다. <Br>
LFU는 여기서 횟수만 세기 때문에, 참조된지 아주 오래된 1을 살리고, **참조 횟수가 가장 적은 4를 죽인다!** **4는 가장 최근에 참조 되었는데도 말이다!** <Br>
확힐히 LFU는 시간에 따른 변화를 반영할 수 없다.


### 5) Clock Algoritm
클럭 알고리즘은 페이지 교체 문제를 하드워어를 통해 해결하려는 알고리즘이다. 기존 방식들은 소프트웨어를 응요한 방식이라 오버헤드가 뒤따랐다. <br>
클럭 알고리즘은 LRU를 근사시킨 알고리즘으로 위의 소프트웨어적인 접근의 문제점을 해결하려 시도한다. <br>
이는 **`Not Used Recently - NUR` 혹은 `Not Recently Used - NRU`라고도 불린다.** <br>
마치 LRU와 같이 , **참조 시점이 가장 오래된 페이지를 스왑아웃한다.** 그리고 하드웨어적 지원으로 동작하여 LRU에 비해 매우 빠르고 효율적이다. <br>
대부분의 시스템에서 페이지 교체 알고리즘을 바로 이 클럭 알고리즘을 택하는 이유이다. <br>

![클럭 알고리즘](https://user-images.githubusercontent.com/71186266/212477892-56c32cca-e562-4aa4-8e76-d056fbaa3d72.jpg)



클럭 알고리즘은 시계와 같은 원형 배열이 있고, 포인터는 한 원소를 가리킨다. **원소는 프레임이다.** <br>

각 프레임의 페이지들은 **참조되는 경우 참조비트가 1로 세팅된다.** <br>
클럭 알고리즘은 **Page Fault가 발생하는 경우 지금 가리키고 있는 프레임을 확인하여 참조 비트가 1인 경우 참조 비트 값을 0으로 바꾼 다음 다음 프레임을 가리킨다.** 마치 시계처럼 말이다. <br>
쉽게 말해 한바퀴 돌면서 이번에 참조된적 없는 페이지 프레임을 찾아내서 교체하는 것이다. <br>
만약 이번에 참조된 페이지를 발견하여 0으로 바꾸어 줬는데, 시계가 한바퀴를 돌아서 다시 처음 만난 프레임으로 돌아왔는데 그 값이 0이라면, **시계가 한바퀴 도는 동안 한번도 참조 안된 인기 없는 페이지라는 것을 알 수 있게 된다.** <br>
결국 이 알고리즘은 최근에 참조가 일어나지 않은 페이지를 교체하는 알고리즘이라고 할 수 있겠다.

## 8.4 전역교체와 지역교체
페이지 교체 알고리즘을 통해, 교체할 페이지를 선택한다고 생각해보자. <br>
현재 실행중인 프로그램은 게임 슈퍼마리오라고 생각해보자. <br>
슈퍼마리오의 실행에 필요한 페이지가 메모리에 없어 Page Fault가 발생했으니 교체할 페이지를 찾을 것인데, **교체할 페이지는 슈퍼마리오가 할당된 페이지들 사이에서 골라야 하는가 아니면 메모리 위의 페이지 프레임 중에서 하나를 골라야 하는가** <br>
전자를 지역교체, 그리고 후자를 전역교체라고 부른다. <br>

전역교체가 어떻게 보면, 다른 프로세스를 괴롭힐 수도 있으므로 안 좋아 보일 수 있다. <br>
**하지만 이 결과는 프로세스별 프레임 할당량을 조절하는 하나의 방법이 될 수 있다.** <br>
자주 참조되지 않는 프로세스는 전역 교체시 자연스럽게 도태되는 것이다. LRU, LFU, 클럭, 그리고 다음 파트에서 나올 Working Set, PFF를 전역교체로 사용하면 프로세스별 프레임 할당을 적절하게 할 수 있다. <Br>
물론 딱딱 용도가 나뉘어 있기 보다는 LRU, LFU를 한 프로세스에만 적용하면 지역교체가 되는 것이다. 내 목적에 따라 귀에 걸면 귀걸이 코에 걸면 코걸이다.


## Reference
- 운영체제와 정보기술의 원리 <반효경 저>  
