# 8. Virtual Memory

우리는 페이징이나 세그멘테이션 등의 방식을 통해  프로그램이 실행되기 위한 모든 관련 내용들을 메모리 위에 올릴 필요가 없어졌다. <br>
운영체제는 CPU에서 **당장 수행해야 하는 부분만을 메모리에 올려두고,** 그렇지 않은 부분은 디스크의 스왑 영역에 내려 놓았다가 다시 필요해지면 올라가 있는 부분과 교체한다. <br>
이제 우리는 8GB 남짓한 메모리를 통해 수십 수백기가 바이트의 게임을 돌릴 수 있는 이유를 알게 되었다. <Br>

운영체제는 자상하다. 운영체제의 도움으로 프로그램은 마치 자기 혼자만이 메모리를 독점한다고 망상할 수 있게 되었다. <br>
프로그램은 마치 자기 혼자 메모리를 쓰는 것처럼 0번지 부터 주소를 사용해 나간다. 그러면 운영체제가 알아서 실제 물리 메모리와 매칭 해준다. 이런 메모리 공간을 **가상 메모리 공간이라고 부른다.** <Br>
각 프로세스는 각자의 가상 메모리 주소를 갖게 된다. <br>
프로세스들이 주소 공간을 메모리에 적재하는 **단위에 따라** `요구 페이징(demand paging)` 방식과, `요구 세그멘테이션(demand segmentation)` 방식으로 나뉘게 되는데, 실제 세상에서는 대부분 **요구 페이징 방식을 사용한다.** <Br> 
<!-- 왜? -->

## 8.1 Demand Pageing
요구 페이징 방식은 이름 그대로, **페이지가 요구될 때만 메모리에 올리는 방식이다.** <br>
처음 부터 모든 데이터를 메모리에 올리는 것이 아니라, **필요한 부분이 요구될 때마다 그떄 그떄 올리는 것이다.** <Br>
당장 필요한 부분만 올리는 덕분에, 메모리를 훨씬 더 효율적으로 쓸수 있었다! 애초에 프로세스별로 기존에 비해 훨씬 작은 영역을 차지하게 되었고, 또 그 큰 내용들 전체를 메모리에 올렸다 내렸다 했던 시절에 비해 오버헤드도 적어진 것이다. <Br>
무엇보다 **메모리 보다 훨씬 큰 프로그램을 돌릴 수 있게 해준 아이디어가 바로 이 Demand Paging이다!** <Br> <br>

이런 Demand Paging 아이디어를 구현하기 위해 어떤 페이지가 현재 메모리에 존재하고, 어떤 페이지가 존재하지 않는지 분명히 알아야 했다. <br>
이를 위해 도입된 것이 **유효-무효 비트이다. (valid-invalud bit)** <br>
유효-무효 비트는 각 프로세스의 모든 페이지에 존재하며, **어떤 페이지가 메모리에 올라가 있는지, 아닌지를 알려준다.** <Br>
당연히 프로세스 시작시엔 모든 페이지의 유효-무효 비트가 0으로 시작한다. **이후, 페이지가 참조되어 메모리에 적재되는 경우 비트값을 1로 바꿔주게 된다.** 그리고 반대로 Disk Swap 영역으로 가는 등, 메모리에서 내려오는 경우엔 비트값이 0으로 바뀌게 된다. <Br> <br>

**CPU가 막 참조하려는 페이지가 메모리 위에 올라가 있지 않는 이유로 유효-무효 비트 값이 0인 경우를 Page Fault라고 부른다.** <br>
참고로 꼭 해당 페이지가 메모리 위에 있지 않을때만 값이 '무효'인건 아니다 <br>
프로세스가 그 페이지가 속한 주소 영역을 사용하지 않을 때도 유효-무효 비트값은 0이다! <br>

## Page Fault 처리
프로세스가 현재 메모리에 올라와 있지 않은 페이지를 참조하려 하면 부슨 일이 일어날까.. <br>
앞서 언급한 것과 같이 Page Fault 상황이 발생하게 된 것이다. <Br>
운영체제는 작업에 필요한 페이지를 불러올 것이다. 그 과정을 살펴보자. <br>

1. 주소 변환을 담당하는 MMU가 **page fault trap을 발생시킨다.** <br> OS에게 필요한 페이지를 불러오는 과정을 맡겨야 하기 때문이다.
2. CPU의 제어권이 커널모드로 변환되고, 페이지 폴트를 일으킨 프로세스는 CPU를 빼앗기고, Blocked State가 된다.
4. OS가 필요한 페이지를 불러오기 전에 일단 **방금의 접근이 적법한지를 먼저 살펴본다.** <Br> 적법 여부는 아래 두가지를 따진다. <br> **i. 사용되는 영역의 페이지에 접근하는가** <Br> **ii. 접근 권한을 위반하고 있지 않은가.** (읽기 전용인데 쓰기 접근을 하는 등)
5. 적법한 경우, 이제 물리 메모리에서 빈 프레임을 찾아 할당 받아, 요구된 페이지를 읽어온다.
6. 빈 프레임이 없는 경우, **현재 메모리에 올라와 있는 페이지 중 하나는 스왑 아웃 시킨다 (쫒아낸다)** <Br> 이후 비어있게 된 공간에 요구 페이지를 스왑-인 시킨다.
7. 요구된 페이지가 디스크에서 메모리에 적재됐으니, **해당 페이지의 유효-무효 비트를 유효로 바꾼다.**
8. 그리고 I/O가 끝났음을 **인터럽트를 발생시켜 알리고,** 해당 프로세스를 Ready Queue로 이동시킨다.

<br>
위의 과정을 모두 거치면 성공적으로 페이지 부재가 해소된다. <Br>

요구 페이징 기법의 성능은 이 페이지 부재 발생 빈도에 달려있다. 보면 알다 싶이 막대한 오버헤드가 발생하기 떄문이다. <Br>

이런 요구 페이징의 성능은 요청된 페이지를 참조하는 데 걸리는 `유효 접근시간`으로 측정하는데, 유효 접근 시간은 페이지 폴트 발생 확률과 메모리 접근 시간의 곱으로 나타난다.

## 2. 페이지 교체 알고리즘 
(다음 문서에서..)

## 3. 페이지 프레임의 할당
여러 프로세스가 동시에 수행될 때, 각 프로세스는 얼만큼의 메모리를 할당 받게 될까? <br>
그리고, **각 프로세스마다 페이지 프레임을 얼마나 할당 해주면 되는걸까?** <br>
페이지 프레임의 크기를 모두 균등하게 할당해 주는 `균등할당 (equal allocation)`도 하나의 방법이다. <Br>
하지만, 시스템의 성능 향상을 위한 **더 나은 메모리 할당 알고리즘이 존재한다.** <br>

1. `비례할당 (proportional allocation)`: 프로세스의 크기에 비례하여 할당해준다.
2. `우선순위 할당 (priority allocation)`: 프로세스의 우선순위에 따라 다르게 할당해준다. <Br> 여기서의 우선순위란 **당장 CPU에서 실행되는지 여부로** 당장 실행될 프로세스에게 나중에 수행될 프로세스보다 더 많은 페이지 프레임을 할당해주는 것이다.

<Br>

한편, 이런 알고리즘들 만으로 프로세스의 페이지 참조 특성을 모두 반영하지 못할 수도 있다. <br>

수행중인 프로세스가 너무 많다면, 프로세스당 너무 적은 양의 페이지 프레임을 할당 받게 되는데, 기본적으로 프로그램이 제대로 돌아가려면 여러 영역을 동시 다발적으로 접근한다는 점을 생각해보면, 계속해서 Page Fault가 발생할 것이 당연하다. <br>
반복문의 경우도 그렇다. 큰 사이즈의 반복문을 수행중인데, 반복문 전체를 올릴 만큼 페이지 프레임을 할당받지 못했다면.. 매 반복마다 계속 스왑아웃-인이 발생하게 되는 것이다. <Br>

페이지 프레임을 할당할 때는 이 모든 것을 고려해야한다. 심지어 어떤 프로세스의 메모리를 다 뺏더라도 다른 프로세스들에게 최소한의 메모리를 할당해줄 수 있어야 한다. 


## Reference
- 운영체제와 정보기술의 원리 <반효경 저>  
