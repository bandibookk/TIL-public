### 불연속 할당 기법
불연속할당 기법은 연속할당 기법과 다르게 **하나의 프로세스를 물리적 메모리의 여러 위치에 분산되어 올리는 방식이다.** <br>
무식하게 연속으로 하지 않고, 일정한 분할 기준을 정해서 나누어서 메모리에 올리자는 것이다! <Br>
이런 불연속 할당 기법에는 페이징과 세그멘테이션 기법이 있다. <br> 
**페이징은 하나의 프로그램을 분할하는 기준에 따라 동일한 크기로 나누어 메모리에 올리는 방식이고,** <Br>
**세그먼테이션은 프로그램을 논리적인 의미 단위로 나누어 올리는 방식이다**. <br> 
그리고 세그멘테이션 기법을 기본으로 하면서도 이를 다시 동일 크기의 페이지로 나누어 메모리에 올리는 페이징을 도입한 페이지드 세그먼테이션 방식이 있다.

# 6.4 페이징 기법
페이징이란 프로세스의 주소 공간을 동일한 크기의 페이지로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 방식이다. <br>
**페이징이 좋은 이유가 뭐냐?** 페이징의 도입으로 각 프로세스의 주소공간 전체를 물리적 메모리에 한꺼번에 올릴 필요가 없어졌다. <Br>
이로 인해 메모리가 프로그램 전체 크기 보다 작아도 실행이 가능한 것이다. <Br>
또 프로세스 주소 공간을 자른만큼, 그와 똑같은 크기로 물리적 메모리도 잘라낼 수 있다. 이 단위를 **프레임** 이라고 부르는데, 페이지와 크기가 같다. <br>
읽으면서 예상했겠지만, 이제 외부 조각 문제는 없다. 프로세스와 메모리를 같은 단위로 잘라 냈으니까, 외부 조각 발생 없이 꽉꽉 채워 넣을 수 있게 되는 것이다. <Br>
어차피 다 같은 크기로 잘라냈으니까, 위치만 제대로 파악할 수 있다면 어디다가 배치해도 된다! <br>
그래서 불연속 할당 기법이 가능해진 것이다. <br>
물론 꼭 프로세스나 메모리가 페이지 크기의 배수만큼의 크기를 가지지 않으므로, 내부 조각이 발생할 수도 있다. 하지만 당연히 프로세스당 1개일테고, 아무리 커봐아 페이지 하나의 크기가 되질 않는다. <Br>
## 4.1 페이지 테이블
이렇게 좋은 페이징을 위해선, 어떤 페이지가 어떤 메모리에 있는지 파악이 잘 되어야 한다. <br>
즉, **논리적 주소를 물리적으로 변환하는 작업이 가능해야 한다.** 페이징에서는 이런 주소 변환을 위해 **모든! 프로세스가 각각! 페이지 테이블을 가지며, 이 테이블은 프로세스가 가질 수 잇는 페이지의 개수만큼 주소 변환 엔트리를 가지고 있게 된다.** 즉, 페이지별로 모든 위치 파악이 가능하다. <br>

페이지 테이블에는 `페이지 테이블 기준 레지스터`와 `페이지 테이블 길이 레지스터`가 존재한다. 기존의 비슷한 구현들과 같이 이 기준 레지스터가 테이블의 시작점을 알리고, 보안을 위해 길이 레지스터가 있는 것이다. <br>

그리고 페이지 테이블의 각 항목에는 보안을 위해 **보호비트와 유효-무효 비트가 있다.** <br>
보호비트는 각 페이지에 대한 접근 권한에 대한 내용을 담고 있다. 어차피 주소공간은 여러 조취로 인해 다른 프로세스 접근이 불가능하기 때문에, **접근 가능한 존재에 관한 정보 보다는 접근이 허용되는 방식에 대해 적혀 있다.** 읽기/쓰기 읽기전용 등의 권한 설정을 위한 비트이다. <br>
유효 무효 비트는 해당 메모리 프레임에 페이지가 존재하는지 여부를 적어 둔다. '무효'로 적혀있는 경우, 프로세스가 그 주소 부분을 사용하지 않거나, 물리적인 메모리에 올라가 있지 않아서 해당 메모리 프레임에 유효한 접근 권한이 없다는 것을 의미한다. 

## 4.2 주소 변환
페이징 기법에서는 CPU가 사용하는 **논리적 주소를 페이지 번호 `p`와 오프셋 `d`로 나누어 주소 변환에 사용한다.** <br>
페이지 번호는 페이지 테이블의 인덱스로 사용된다. 페이지 테이블엔 페이지가 순서대로 배치되어 있다. 페이지 번호로 해당 엔트리를 찾아내면, **그 페이지의 물리적 메모리 기준 주소가 있다.** <br>
그리고 **그 기준 주소에 오프셋 `d`를 더하면 논리적 주소에 대응하는 물리적 주소를 얻을 수 있게 된다.**


## 4.3 TLB
그런데 페이지 테이블을 사용함에도 오버헤드는 있다. <br>
1. 주소 변환을 위해 페이지 테이블에 접근함
2. 변환된 주소에서 실제 데이터에 접근

이렇게 총 두 번의 메모리 접근이 필요하다는 오버헤드가 있다. 이런 오버헤드를 줄이고 메모리 접근 속도를 향상 시키기 위해 **페이지 테이블을 위한 일종의 캐시로서 TLB (Translation Look-aside Buffer)가 제안되었다.** <br>
**TLB는 고속 주소 변환용 하드웨어 캐시로, 병렬적으로 모든 엔트리를 한번에 탐색한다!** <br>
당연히 매우 작다. 변환하려는 논리 주소가 이미 TLB에 있다면, TLB의 것을 우선적으로 쓴다. 없으면 원래대로 페이지 테이블에서 찾는다. <br>
문맥 교환시 TLB의 정보는 모두 지운다. <br>


## 4.4 계층적 페이징
시대가 흐르며 메모리의 크기는 커졌다. <br>
32 비트 주소 체계 컴퓨터에서는 2^32 byte의 주소 공간을 갖는 프로그램을 지원할 수 있는데, 페이지의 크기가 4KB라면 무려 1M개의 페이지 테이블 엔트리가 필요하게 된다. <br>
페이지 테이블만을 위해 어마어마한 메모리를 소비하게 되는 것이다 <br>
이런 페이지 테이블에 사용되는 메모리 공간의 낭비를 줄이기 위해 **2단계 페이징 기법이 사용되었다.** <br>

2단계 페이징에선 외부 페이지 테이블과 내부 페이지 테이블의 두 테이블이 사용된다. <br>
외부 페이지 테이블에서는 사용하는 공간만 남기고 나머지는 NULL로 처리한다. 그리고 외부 페이지 테이블의 엔트리 하나당 내부 페이지 테이블로 연결된다. <br>

이렇게 메모리 사용량을 많이 줄일 수 있지만, 아무래도 거치는 테이블이 하나 더 늘었으므로 시간은 더 소비된다. 메모리-타임 트레이드 오프에 해당한다. <br>

2단계 페이징 기법에서는 주소가 3개의 부분으로 나뉜다. 첫 번째 부터 외부 테이블의 인덱스, 내부 테이블의 인덱스, 그리고 오프셋이다. <br>
그냥 테이블 하나를 더 거친다고 생각하면 된다. <br>
이런 오버해드는 또 TLB를 도입하면서 대폭 줄일 수가 있다. TLB를 도입하면 무려 4단계 페이지 테이블까지 늘려도 기존 2단계 페이지 테이블을 사용할 때보다 시간이 적게 걸리게 된다. 

## 4.5 공유 페이지
공유 페이지란 공유 코드를 담고 있는 페이지를 뜻한다. <br>
같은 프로그램이 여러개 올라가 있을 때, 분명히 겹치는 부분이 있을 것이다. <Br>
공유 페이지는 이 겹치는 부분이 담긴 페이지를 하나만 올리고, 여러 프로세스가 이 공유 페이지를 '공유'하게 한다. <Br>
단, 공유 페이지가 되기 위해선 만족해야 하는 조건이 있는데, **공유 페이지는 읽기 전용의 성질을 가져야 하고, 모든 프로세스의 논리적 주소 공간에서 동일한 위치에 존재해야 한다.** <br>
겹치지 않는 부분은 사유 페이지라고 부르며 논리적 주소 공간 중 어느 위치에 있어도 상관없다.



## Reference
- [반효경 교수 OS 강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323)
